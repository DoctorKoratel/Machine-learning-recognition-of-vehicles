\documentclass[a4paper,14pt]{extarticle} %размер бумаги устанавливаем А4, шрифт 14пунктов
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm,bindingoffset=0cm]{geometry} % Меняем поля страницы
\usepackage{setspace}
\onehalfspacing % Полуторный интервал

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[english,russian]{babel} %используем русский и английский языки с переносами
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float} %подключаем нужные пакеты расширений

\usepackage[pdftex]{graphicx, color}
\usepackage{subfigure}
\usepackage{color}
\usepackage{listings}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{pdflscape}

\usepackage{longtable}

\usepackage{url}

\usepackage{float}
\floatname{algorithm}{Листинг}

\DeclareGraphicsExtensions{.png,.pdf,.jpg,.mps,.bmp}
\usepackage{bmpsize}

\usepackage[nooneline]{caption} \captionsetup[table]{justification=raggedleft} \captionsetup[figure]{justification=centering,labelsep=endash}

\begin{document} 
\renewcommand{\figurename}{Рисунок}
\renewcommand{\baselinestretch}{1.5}
\renewcommand{\abstractname}{{Аннотация}}

\begin{titlepage}
\newpage
\begin{center}
Государственное образовательное учреждение высшего профессионального образования \\
\vspace{1cm}
\Large<<Московский государственный технический университет имени Н.Э. Баумана>> \\*
(МГТУ им. Н.Э. Баумана) \\*
\hrulefill
\end{center}
\flushright{ФАКУЛЬТЕТ ИНФОРМАТИКИ И СИСТЕМ УПРАВЛЕНИЯ}
\flushright{КАФЕДРА ТЕОРЕТИЧЕСКОЙ ИНФОРМАТИКИ И КОМПЬЮТЕРНЫХ ТЕХНОЛОГИЙ}
\vspace{8em}
\begin{center}
\Large  Отчет о НИРС
\end{center}
\vspace{8em}
\begin{flushleft}
Студент \hrulefill Батусов П. В. \\
\vspace{1.5em}
Научный руководитель \hrulefill Вишняков И. Э.\\
\vspace{1.5em}
\end{flushleft}
\vspace{\fill}
\begin{center}
Москва 2016
\end{center}
\end{titlepage}

\renewcommand{\contentsname}{\centering Содержание}
\tableofcontents
\newpage

\section{Цели обзора}
\hspace{\parindent} В данном отчете представлены основные подходы для решения одной из задач машинного обучения --- классификации и определения объектов на изображении. Рассматриваемые методы можно условно разделить на две группы: алгоритмы классификации с использованием признаков и классификаторы, которые выводят признаки в процессе обучения. 

Главной целью обзора является разбор существующих систем решений, изучение их устройства и архитектуры, выбор оптимального подхода для решения задачи распознавания модели автомобиля по фотографии. В конце отчета предоставлен план дальнейших исследований и тестирования.

\section{Существующие подходы определения и классификации объектов на изображении}

\subsection{Классификация по признакам}
\hspace{\parindent} В данном пункте рассматриваются алгоритмы решения задачи распознавания автомобилей по цифровому изображению, полученному с камер дорожного наблюдения, авторегистраторов и т. д.. Перечисленные подходы основаны на обработке известной информации о структуре объектов, которые необходимо определить и классифицировать, а также использовании фактов о ракурсе съемке, погодных условиях и прочем для увеличения итоговой точности. Другими словами, эти методы работают с известными признаками объектов.

\subsubsection{Выделение признаков по трехмерной структуре}
\hspace{\parindent} Данный метод~\cite{wu2001method} основан на представлении автомобилей в виде полигональной модели, по которой происходит выделение признаков, передаваемых на вход нейросети. Трехмерная структура описания автомобиля разделена на восемь частей, в каждой из которых выделяется опорная вершина. В качестве признаков используется расстояние между каждой парой опорных вершин. Дополнительно рассматриваются параметры колес автомобиля, их радиус и положение.

Авторы работ использовали трехслойную, полносвязную нейронную сеть с 30 входами (количество признаков) и 120 выходами ($6 \times 20$, 6 --- количество классов, 20 --- число выходных нейронов для каждого класса). Результат определялся поиском максимального значения в выходном слое. 

При обучении сети использовался метод обратного распространения ошибки. В качестве функции ошибки, для улучшения сходимости, использовалась экспоненциальная функция вместо квадратичной. 

Обучающая выборка состояла из 500 изображений с дорожных камер. Классификация производилась на большие/небольшие грузовики и автомобили. Тестовая выборка включала в себя еще 300 изображений, из которых правильно классифицировано 91\%, ошибочно 4\% и в 5\% случаев система не смогла определить автомобиль на изображении.

\subsubsection{Применение цепочки классификаторов}
\hspace{\parindent} В работе~\cite{brehar2010pillars} ставилась задача определения боковых стоек автомобиля. Решение задачи представляло собой многослойную схему классификации, от общего к частному. Такой подход называют усилением простых классификаторов (boosting classifier). Первые слои предназначены для обработки входного изображения, определения направления движения, колес, выделение боковой части автомобиля и только после этого производится поиск боковых стоек на основе гистограммы ориентированных градиентов и геометрических моделей.

Обучение системы производилось на изображениях автомобильного потока, в тестовую выборку также включены негативные примеры, не содержащие транспортных средств. Обучающее множество состоит из 100000 изображений без автомобилей и 4000 с автомобилями. Тестовая выборка содержит 1000 положительных и 200000 негативных примеров. Итоговая точность составила 90\% для положительных и 99\% --- для негативных примеров.

\subsubsection{Байесовские сети} 
\hspace{\parindent} Имея возможность выделения признаков для дальнейшего решения задачи классификации, можно воспользоваться байесовской сетью. Такой подход использовался в работе выделения автомобилей на фотоаэроснимках низкого разрешения~\cite{zhao2003car}. Основная проблема при решении этой задачи --- высокое количество шумов: тени, солнечные блики, кроны деревьев и прочее.

Авторы предложили метод, основанный на использовании дополнительной известной информации о времени и месте съемки. Эти данные и выделенные признаки объектов вместе попадают в байесовскую сеть, которая производит отсев таких неправильно определенных кандидатов, как тени от настоящих автомобилей и объектов, находящихся вне дорожного полотна. 

\subsubsection{Поиск выделенных признаков в базе данных}
\hspace{\parindent} Car-Rec~\cite{jang2011car} --- еще одно предложенное решение для задачи классификации автомобилей, заключающееся в выделении признаков и их обработке с использованием деревьев поиска по заготовленной базе. Для определения области поиска на изображении используется алгоритм SURF~\cite{bay2008speeded}, основанный на интегральном представлении входного изображения. Разработанная система имеет точность более 90\%.

\subsection{Классификация без явного определения признаков}
\hspace{\parindent} Не всегда имеется возможность выделения опорных признаков для классификации, так как в общем случае не понятно, по какому принципу их выбирать. Кроме этого, неизвестно, как с течением времени будет развиваться предметная область, и какие еще признаки необходимо зарезервировать для дополнительных классов. 

При использовании нейросетей признаки для классификации автоматически вырабатываются при обучении модели. В случае необходимости добавить новые классы в классификатор, производят его переобучение, в результате чего выводятся новые признаки. Также возможно произвести более быструю настройку, скорректировав весовые коэффициенты без перестроения признаков (дообучение сети).

\subsubsection{Глубокие сети доверия} 
\hspace{\parindent} Глубокие сети доверия~\cite{wang2014vehicle} являются развитием идеи использования рекуррентных нейронных сетей, которые тяжело обучать из-за наличия обратных связей. Рассматривается архитектура, при которой внутри скрытых слоев используется ограниченная машина Больцмана. 

Авторы рассматривают задачу определения автомобиля по фотографии сзади (как с камеры авторегистратора). Входной слой имеет размерность, соответствующую разрешению изображения (признаки --- пикселы). Данные классифицируются по двум категориям: автомобиль и не автомобиль.

Тестирование происходило на 735 изображениях, рассматривались модели с одним, двумя и тремя скрытыми слоями. Наилучшая точность была получена при использовании двух скрытых слоев --- более 96\%. Также была произведена оценка точности для других алгоритмов: искуственных и сверточных нейросетей, $k$ ближайших соседей и метода опорных векторов. Среди них наибольшая точность результата получилась при использовании сверточных нейронных сетей, почти 95\%.

\subsubsection{Сверточные нейронные сети}
\hspace{\parindent} В работе~\cite{sermanet2012convolutional} рассматривалась задача распознавания номерных табличек на домах. Использовалась традиционная архитектура сверточной нейросети: первый сверточный слой выделял 16 карт признаков со сверткой $5 \times 5$, второй --- 512, со сверткой $7 \times 7$, два слоя классификации по 20 нейронов каждый. Применялся многоступенчатый подход выделения признаков (слоям классификации были доступны все предыдущие карты признаков). Описанная модель реализована на фреймворке EBLearn~\cite{sermanet2009eblearn}.

Был произведен подбор оптимального параметра степени свертки для алгоритма выделения признаков Lp-Pooling. Наилучшая точность получена при использовании коэффициента $p=4$. Кроме этого, перед передачей изображения в сеть, вокруг него достраивалась рамка из двух пикселов с нулевым значением, чтобы граница попадала в операцию свертки рамкой $5 \times 5$ в разных положениях.

Набор данных состоял из обучающей, тестовой и дополнительной выборок. Дополнительная выборка состояла из большого количества легких для классификации изображений, а обучающая содержала небольшое число более сложных примеров. Обучение происходило на 6000 примеров, выбранных случайным образом из обучающего множества ($2/3$) и из дополнительного ($1/3$). В результате при тестировании была получена точность более 95\%.

\subsubsection{Глубокие сверточные нейронные сети}
\hspace{\parindent} Один из вопросов систем распознавания и классификации изображений --- насколько большую предметную область можно охватить, используя автоматические методы. В рамках состязания ILSVRC~\cite{ILSVRC} проводится попытка классифицировать огромный тестовый набор изображений (более миллиона) по тысяче категорий.

Авторы работы~\cite{krizhevsky2012imagenet} занимались созданием одной из самых больших сверточных нейросетей для участия в ILSVRC-2012. Она состояла из 5 сверточных и 3 полносвязных слоев, включающих 60 миллионов параметров и 650 тысяч нейронов. В работе отмечена необходимость и важность большой размерности сети, так как при попытке избавиться хотя бы от одного слоя происходило сильное падение качества классификатора. 

Для уменьшения вероятности переобучения использовался подход выбывающих нейронов~\cite{srivastava2014dropout}. В качестве активационной функции была выбрана модель параметрического выпрямляемого элемента ReLU~\cite{dahl2013improving}. При тестировании по мере оценки ошибки top-5 error (смотрится результат среди пяти самых вероятных классов, выделенных сетью) была получена точность 84.7\%.

На соревнованиях ILSVRC-2014 была представлена еще большая сеть, включающая 27 слоев~\cite{szegedy2014going}. Команде GoogLeNet получилось добиться результатов в 6.67\% ошибок.

\subsubsection{Плиточные сверточные нейронные сети}
\hspace{\parindent} Сверточные нейронные сети хорошо применяются для задач классификации и распознавания объектов, однако, подход использующий разделяемые веса может помешать в процессе обучения выделить некоторые инвариантные признаки. В работе~\cite{ngiam2010tiled} предлагался метод, в котором разделяемые веса чередовались с некоторым шагом $k$. Так, при $k=1$ получалась обычная сверточная нейронная сеть, а при увеличении этого параметра строилась очередная модель, которая является компромиссом между способностью выявления инвариантности изображений и сложностью обучения системы.

Тестирование производилось на наборе данных CIFAR-10~\cite{krizhevsky2009learning}, состоящем из 50000 обучающих изображений и 10000 тестовых, которые необходимо классифицировать по 10 категориям.Полученная точность метода при выбранном параметре $k=2$ более 73\%.

\section{Выбранная модель}
\hspace{\parindent} Согласно поставленным целям были рассмотрены существующие алгоритмы автоматической классификации объектов на изображении. Применительно для решения задачи НИРС определения модели автомобиля по фотографии был выбран подход использования нейронных сетей.

\subsection{Обучение нейронных сетей}
\hspace{\parindent} В этом пункте рассматриваются алгоритмы и их модификации для эффективного обучения нейронных сетей, разделение процесса обучения на независимые подзадачи и их вычисление на графическом процессоре управления. Кроме этого, приведен пример переобучения сети на более узкую предметную область без перестроения выделенных признаков, что говорит о возможности дообучения классификатора.

\subsubsection{Эффективное обратное распространение ошибки}
\hspace{\parindent} Обратное распространение ошибки --- это один из классических методов обучения нейронных сетей, так как данный подход является простым при реализации, вычислительно не очень сложным и почти всегда работающим. Однако, его применение для получения действительно высоких результатов требует подбора большого числа параметров. В работе~\cite{lecun2012efficient} приведены различные способы, применяемые исследователями для повышения результатов классификации при обучении сети, и их обоснование.

Основные проблемы алгоритма обратного распространения ошибки --- это низкая скорость обучения глубоких сетей и попадание в точки локальных минимумов задачи оптимизации. Для ускорения без существенной потери точности можно воспользоваться стохастическим градиентным спуском. Кроме этого, рассматривались подходы нормализации входных переменных при обучении, перемешивания обучающей выборки, выбора активационной функции и способов начальной инициализации весов.

\subsubsection{Использование графического процессора}
\hspace{\parindent} Использование обучения без учителя позволяет обрабатывать огромные неразмеченные наборы данных и автоматически устанавливать взаимосвязи предметной области. Такой подход удобен тем, что не нужно собирать обучающую и тестовую выборки, которые приходится размечать вручную. С другой стороны, при таком обучении требуется выполнить намного больше вычислительных операций, из-за чего приходится отказываться от использования ЦПУ. 

В статье~\cite{raina2009large} рассматривался пример обучения четырехслойной модели глубокой сети доверия со 100 миллионами настраиваемых параметров на графическом процессоре Nvidia GeForce GTX 280 с объемом оперативной памяти 1Гбайт. Программирование под CUDA SDK. Основная идея заключалась в минимизации числа операций обмена данными между ОЗУ и локальной памятью графического процессора. В итоге было получено увеличение скорости классификации в 5-15 раз по сравнению с вычислениями на ЦПУ.

\subsubsection{Дообучение сети}
\hspace{\parindent} Обучение нейросетей требует много времени на подготовку данных для обучающей выборки и тестирования, а также решение многомерной задачи оптимизации. При необходимости добавить в классификатор новый подкласс рассматриваемой предметной области не всегда есть возможность выполнить полное переобучение сети. Однако, можно попробовать произвести корректировку весов в полносвязных слоях без перестроения признаков.

Такой эксперимент был проведен в работе~\cite{reyes2015fine}. После обучения сети на широком классе задачи распознавания растений ее последний классификационный слой был инициализирован случайными весами, а затем произведено дообучение с применением алгоритма стохастического градиентного спуска на более узком подклассе. Скорость обучения задавалась для каждого слоя в отдельности, наименьший шаг использовался для полносвязных слоев классификации. 

С первых итераций корректировки весов наблюдался резкий подъем точности классификации, однако кривая обучения очень быстро вышла на плато в 60-65\% для нового подкласса с использованием старых признаков. Сеть выделяла тысячу различных классов. Все вычисления производились с использованием фреймворка Caffe на графическом процессоре NVIDIA Titan~Z.

\subsection{Определение параметров сети}

\subsubsection{Размер сети}

\subsubsection{Формирование обучающей выборки}

\subsubsection{Процедура обучения}

\section{План дальнейших исследований}
\hspace{\parindent} 

%
\newpage
\bibliographystyle{gost780u}  %% стилевой файл
\begin{flushleft}
\bibliography{biblio}     %% имя библиографической базы (bib-файла) 
\end{flushleft}

\end{document}